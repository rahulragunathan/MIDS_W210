{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import movie files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_file = 'movies2010_2016.csv'\n",
    "plot_file = 'plots2010_2016.csv'\n",
    "actor_file = 'actors2010_2016.csv'\n",
    "director_file = 'directors2010_2016.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv(movie_file)\n",
    "plot_df = pd.read_csv(plot_file)\n",
    "actor_df = pd.read_csv(actor_file)\n",
    "director_df = pd.read_csv(director_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print movie_df.columns.values\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print movie_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print plot_df.columns.values\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print plot_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print actor_df.columns.values\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print actor_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print director_df.columns.values\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print director_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_list_df = movie_df.merge(plot_df, on=[u'site'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print movie_list_df.columns.values\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print movie_list_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert revenues to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_arr = []\n",
    "for index, row in movie_list_df.iterrows():\n",
    "    try:\n",
    "        revenue = float(row['revenues'])\n",
    "    except:\n",
    "        revenue = np.nan\n",
    "    revenue_arr.append(revenue)\n",
    "\n",
    "movie_list_df['revenues_clean'] = revenue_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert length to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length_arr = []\n",
    "for index, row in movie_list_df.iterrows():\n",
    "    try:\n",
    "        length = re.sub(\"[^0-9]+\", \"\", row['length'])\n",
    "        length = int(length)\n",
    "    except:\n",
    "        length = np.nan\n",
    "    length_arr.append(length)\n",
    "\n",
    "movie_list_df['length_clean'] = length_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace nulls in text columns with empty string (otherwise sometimes causes error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_list_df['based_on'].replace(to_replace=np.nan, value=\"\", inplace=True)\n",
    "movie_list_df['cinematography'].replace(to_replace=np.nan, value=\"\", inplace=True)\n",
    "movie_list_df['country'].replace(to_replace=np.nan, value=\"\", inplace=True)\n",
    "movie_list_df['director'].replace(to_replace=np.nan, value=\"\", inplace=True)\n",
    "movie_list_df['plot'].replace(to_replace=np.nan, value=\"\", inplace=True)\n",
    "movie_list_df['starring'].replace(to_replace=np.nan, value=\"\", inplace=True)\n",
    "movie_list_df['studio'].replace(to_replace=np.nan, value=\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print movie_list_df.columns.values\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print movie_list_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add release week and day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "week_arr = []\n",
    "day_of_week_arr = []\n",
    "for index, row in movie_list_df.iterrows():\n",
    "    try:\n",
    "        release_year = int(row['release_year'])\n",
    "        release_month = int(row['release_month'])\n",
    "        release_day = int(row['release_day'].split(\"-\")[0])\n",
    "        release_week = datetime.date(release_year, release_month, release_day).isocalendar()[1]\n",
    "        release_day_of_week = datetime.datetime.weekday(datetime.datetime.strptime(str(release_year)+\"-\"+str(release_month)+\"-\"+str(release_day), \"%Y-%m-%d\"))\n",
    "    except:\n",
    "        release_week = np.nan   \n",
    "        release_day_of_week = np.nan\n",
    "    day_of_week_arr.append(release_day_of_week)\n",
    "    week_arr.append(release_week)\n",
    "\n",
    "movie_list_df['release_week'] = week_arr\n",
    "movie_list_df['release_day_of_week'] = day_of_week_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split director, actor, etc. arrays in to individual features\n",
    "Retain top n results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_top_actors = 10\n",
    "actor_col_arr = [\"actor_\" + str(i) for i in range(no_top_actors)]\n",
    "actor_arr = []\n",
    "for index, row in movie_list_df.iterrows():\n",
    "    actor_list = row['starring'].split()[:no_top_actors]\n",
    "    actor_arr.append(actor_list)\n",
    "\n",
    "actor_arr = np.transpose(actor_arr)\n",
    "    \n",
    "for topic in enumerate(actor_col_arr):\n",
    "#    movie_list_df[topic[1]] = actor_arr[topic[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print movie_list_df.columns.values\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print movie_list_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decompose plots into topics using Non-Negative Matrix Factorization (NNMF), Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "no_word_features = 1000\n",
    "no_topics = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print movie_list_df['plot'][1]\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print movie_list_df['plot'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_list_df['plot_clean'] = movie_list_df['plot'].replace(to_replace='\\[[0-9]+\\]', value=\" \", regex=True)\n",
    "movie_list_df['plot_clean'].replace(to_replace='[^A-Za-z0-9]+', value=\" \", inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use NLTK to remove proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print movie_list_df['plot_clean'][1]\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print movie_list_df['plot_clean'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print movie_list_df.columns.values\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print movie_list_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit NNMF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize plots for NNMF using tf-idf\n",
    "Max number of features is number of words for the \"bag of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnmf_tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_word_features, stop_words='english')\n",
    "nnmf_tfidf = nnmf_tfidf_vectorizer.fit_transform(movie_list_df['plot_clean'])\n",
    "nnmf_tfidf_feature_names = nnmf_tfidf_vectorizer.get_feature_names()\n",
    "print nnmf_tfidf_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run NNMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnmf_model = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(nnmf_tfidf)\n",
    "nnmf_W = nnmf_model.transform(nnmf_tfidf)\n",
    "nnmf_H = nnmf_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add full list of NNMF topic scores to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_list_df['nnmf_topic_scores'] = nnmf_W.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add top n NNMF topics to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_top_n_nnmf_topics = 4\n",
    "nnmf_topic_arr = [\"nnmf_topic_\" + str(i) for i in range(no_top_n_nnmf_topics)]\n",
    "top_n_nnmf_topic_arr = []\n",
    "for index, row in movie_list_df.iterrows():\n",
    "    top_n_nnmf_topic_arr.append(np.array(row['nnmf_topic_scores']).argsort()[-1*no_top_n_nnmf_topics:][::-1])\n",
    "\n",
    "top_n_nnmf_topic_arr = np.transpose(top_n_nnmf_topic_arr)\n",
    "    \n",
    "for topic in enumerate(nnmf_topic_arr):\n",
    "    movie_list_df[topic[1]] = top_n_nnmf_topic_arr[topic[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print movie_list_df.columns.values\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print movie_list_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit LDA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize plots for LDA using tf\n",
    "Max number of features is number of words for the \"bag of words\".\n",
    "\n",
    "LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_word_features, stop_words='english')\n",
    "lda_tf = lda_tf_vectorizer.fit_transform(movie_list_df['plot_clean'])\n",
    "lda_tf_feature_names = lda_tf_vectorizer.get_feature_names()\n",
    "print lda_tf_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(lda_tf)\n",
    "lda_W = lda_model.transform(lda_tf)\n",
    "lda_H = lda_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add LDA topics to main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_list_df['lda_topic_scores'] = lda_W.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add top n LDA topics to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_top_n_lda_topics = 4\n",
    "lda_topic_arr = [\"lda_topic_\" + str(i) for i in range(no_top_n_lda_topics)]\n",
    "top_n_lda_topic_arr = []\n",
    "for index, row in movie_list_df.iterrows():\n",
    "    top_n_lda_topic_arr.append(np.array(row['lda_topic_scores']).argsort()[-1*no_top_n_lda_topics:][::-1])\n",
    "\n",
    "top_n_lda_topic_arr = np.transpose(top_n_lda_topic_arr)\n",
    "    \n",
    "for topic in enumerate(lda_topic_arr):\n",
    "    movie_list_df[topic[1]] = top_n_lda_topic_arr[topic[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print movie_list_df.columns.values\n",
    "print \"---------------------------------------------------------------------------\"\n",
    "print movie_list_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display plot model results\n",
    "Will display top associated words, top movies for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_top_words = 50\n",
    "no_top_documents = 5\n",
    "\n",
    "def display_topics(H, W, feature_names, titles, plots, no_top_words, no_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print \"Topic %d:\" % (topic_idx)\n",
    "        print \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            print \"\\nMovie: \" + titles[doc_index]\n",
    "            print \"Plot:\\n\" + plots[doc_index] + \"\\n\"\n",
    "        print \"---------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_topics(nnmf_H, nnmf_W, nnmf_tfidf_feature_names, movie_list_df['title'], movie_list_df['plot'], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_topics(lda_H, lda_W, lda_tf_feature_names, movie_list_df['title'], movie_list_df['plot'], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Build revenue prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create model input array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create numpy array with specific columns from pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_prediction_features = ['length_clean', 'release_week', 'release_day_of_week']\n",
    "movie_prediction_features += lda_topic_arr\n",
    "revenue_column = ['revenues_clean'] \n",
    "\n",
    "revenue_actl = np.array(movie_list_df[revenue_column]).flatten()\n",
    "movie_feature_arr = np.array(movie_list_df[movie_prediction_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print revenue_actl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print movie_prediction_features\n",
    "print movie_feature_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data set into training, validation, and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, training_revenue = movie_feature_arr[:600], revenue_actl[:600]\n",
    "validation_data, validation_revenue = movie_feature_arr[601:1000], revenue_actl[601:1000]\n",
    "test_data, test_revenue = movie_feature_arr[1001:], revenue_actl[1001:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create function to evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squared Error Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetSquaredErrorLoss(revenue_actl, revenue_pred):\n",
    "    return sum((np.nan_to_num(revenue_actl - revenue_pred))**2)/(1.0*len(revenue_actl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print GetSquaredErrorLoss(revenue_actl, revenue_actl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict results of validation data set using training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict using a variety of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using \"train\" data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(training_data, training_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict revenues of validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm_validation_revenue_pred = np.round(lm.predict(validation_data))\n",
    "lm_validation_revenue_pred[lm_validation_revenue_pred < 0] = 0\n",
    "print lm_validation_revenue_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm_error = GetSquaredErrorLoss(validation_revenue, lm_validation_revenue_pred)\n",
    "print lm_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Regressor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
